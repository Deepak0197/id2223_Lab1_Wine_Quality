{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4737d1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakshankar/opt/anaconda3/envs/ML_DL/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "    import hopsworks\n",
    "    import pandas as pd\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "    import seaborn as sns\n",
    "    from matplotlib import pyplot\n",
    "    from hsml.schema import Schema\n",
    "    from hsml.model_schema import ModelSchema\n",
    "    import joblib\n",
    "    import os\n",
    "    \n",
    "    \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c094a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/210070\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "# You have to set the environment variable 'HOPSWORKS_API_KEY' for login to succeed\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7acc460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/210070/fs/209989/fv/wine/version/1\n"
     ]
    }
   ],
   "source": [
    "# The feature view is the input set of features for your model. The features can come from different feature groups.    \n",
    "# You can select features from different feature groups and join them together to create a feature view\n",
    "wine_fg = fs.get_feature_group(name=\"wine\", version=1)\n",
    "query = wine_fg.select_all()\n",
    "feature_view = fs.get_or_create_feature_view(name=\"wine\",\n",
    "                                  version=1,\n",
    "                                  description=\"Read from Wine quality dataset\",\n",
    "                                  labels=[\"quality\"],\n",
    "                                  query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca8317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Could not establish connection to ArrowFlight Server. (Flight returned timeout error, with message: Deadline Exceeded) Will fall back to hive/spark for this session. If the error persists, you can disable using ArrowFlight by changing the cluster configuration (set 'enable_flyingduck'='false').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hive (5.03s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `1`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can read training data, randomly split into train/test sets of features (X) and labels (y)        \n",
    "X_train, X_test, y_train, y_test = feature_view.train_test_split(0.2)\n",
    "\n",
    "# # Train our model with the Scikit-learn K-nearest-neighbors algorithm using our features (X_train) and labels (y_train)\n",
    "# model = KNeighborsClassifier(n_neighbors=2)\n",
    "# model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960bb7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=52)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, random_state=52)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=52)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# You can read training data, randomly split into train/test sets of features (X) and labels (y)        \n",
    "# X_train, X_test, y_train, y_test = feature_view.train_test_split(0.2)\n",
    "\n",
    "# # Train our model with the Scikit-learn K-nearest-neighbors algorithm using our features (X_train) and labels (y_train)\n",
    "# model = KNeighborsClassifier(n_neighbors=2)\n",
    "# model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rfc_model = RandomForestClassifier(n_estimators=200, random_state=52)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rfc_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "489180ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.7445864661867806\n"
     ]
    }
   ],
   "source": [
    "#For Random forest regressor\n",
    "import numpy as np\n",
    "from numpy import round\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_rf_pred = np.round(rf_model.predict(X_test))\n",
    "\n",
    "# Evaluate the model. Not to be used for Classification.\n",
    "mse = mean_squared_error(y_test, y_rf_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55c86b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set, for Random forest classifier\n",
    "y_rfc_pred = np.round(rfc_model.predict(X_test))\n",
    "\n",
    "# # Compare predictions (y_rfc_pred) with the labels in the test set (y_test)\n",
    "metrics = classification_report(y_test, y_rfc_pred, output_dict=True, zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8a4547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}, '4': {'precision': 0.125, 'recall': 0.047619047619047616, 'f1-score': 0.06896551724137931, 'support': 42}, '5': {'precision': 0.4462616822429907, 'recall': 0.5190217391304348, 'f1-score': 0.4798994974874372, 'support': 368}, '6': {'precision': 0.4490909090909091, 'recall': 0.5416666666666666, 'f1-score': 0.49105367793240556, 'support': 456}, '7': {'precision': 0.30985915492957744, 'recall': 0.13496932515337423, 'f1-score': 0.18803418803418803, 'support': 163}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 32}, '9': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'accuracy': 0.4333958724202627, 'macro avg': {'precision': 0.4757445351804968, 'recall': 0.17761096836707477, 'f1-score': 0.1754218400993443, 'support': 1066}, 'weighted avg': {'precision': 0.40315834508855186, 'recall': 0.4333958724202627, 'f1-score': 0.4071947622760454, 'support': 1066}}\n"
     ]
    }
   ],
   "source": [
    "# # Train our model with the Scikit-learn K-nearest-neighbors algorithm using our features (X_train) and labels (y_train)\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_knn_pred = np.round(model.predict(X_test))\n",
    "\n",
    "metrics = classification_report(y_test, y_knn_pred, output_dict=True, zero_division=1)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33526dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>ph</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.053</td>\n",
       "      <td>25.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.99760</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.050</td>\n",
       "      <td>26.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.99884</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.039</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.99215</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.034</td>\n",
       "      <td>43.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99220</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.69</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.018</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99004</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.52</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.037</td>\n",
       "      <td>37.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.99670</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.44</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5324</th>\n",
       "      <td>1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.37</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.033</td>\n",
       "      <td>52.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.99726</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.79</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325</th>\n",
       "      <td>1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.37</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.043</td>\n",
       "      <td>64.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.99632</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.020</td>\n",
       "      <td>24.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98980</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.47</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.31</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.045</td>\n",
       "      <td>34.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.99226</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.55</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4264 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \\\n",
       "1        1            7.4              0.28         0.25            11.9   \n",
       "2        1            7.5              0.24         0.31            13.1   \n",
       "4        1            8.3              0.14         0.45             1.5   \n",
       "5        1            6.4              0.15         0.36             1.8   \n",
       "6        1            7.1              0.12         0.30             3.1   \n",
       "...    ...            ...               ...          ...             ...   \n",
       "5323     1            7.9              0.16         0.30             4.8   \n",
       "5324     1            7.6              0.19         0.37            13.1   \n",
       "5325     1            6.7              0.24         0.37            11.3   \n",
       "5326     1            6.0              0.27         0.19             1.7   \n",
       "5327     1            6.8              0.33         0.31             7.4   \n",
       "\n",
       "      chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    ph  \\\n",
       "1         0.053                 25.0                 148.0  0.99760  3.10   \n",
       "2         0.050                 26.0                 180.0  0.99884  3.05   \n",
       "4         0.039                 18.0                  98.0  0.99215  3.02   \n",
       "5         0.034                 43.0                 150.0  0.99220  3.42   \n",
       "6         0.018                 15.0                  37.0  0.99004  3.02   \n",
       "...         ...                  ...                   ...      ...   ...   \n",
       "5323      0.037                 37.0                 171.0  0.99670  3.47   \n",
       "5324      0.033                 52.0                 151.0  0.99726  3.18   \n",
       "5325      0.043                 64.0                 173.0  0.99632  3.08   \n",
       "5326      0.020                 24.0                 110.0  0.98980  3.32   \n",
       "5327      0.045                 34.0                 143.0  0.99226  3.06   \n",
       "\n",
       "      sulphates  alcohol  \n",
       "1          0.62      9.2  \n",
       "2          0.53      9.1  \n",
       "4          0.56     11.0  \n",
       "5          0.69     11.0  \n",
       "6          0.52     11.9  \n",
       "...         ...      ...  \n",
       "5323       0.44      9.0  \n",
       "5324       0.79     10.4  \n",
       "5325       0.53      9.9  \n",
       "5326       0.47     12.6  \n",
       "5327       0.55     12.2  \n",
       "\n",
       "[4264 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc8d25d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5324</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4264 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      quality\n",
       "1           5\n",
       "2           6\n",
       "4           6\n",
       "5           8\n",
       "6           7\n",
       "...       ...\n",
       "5323        4\n",
       "5324        6\n",
       "5325        6\n",
       "5326        7\n",
       "5327        6\n",
       "\n",
       "[4264 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22f101c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>ph</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>3.04000</td>\n",
       "      <td>0.58000</td>\n",
       "      <td>11.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.99058</td>\n",
       "      <td>3.10000</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>11.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.99685</td>\n",
       "      <td>3.32000</td>\n",
       "      <td>0.55000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>3.28000</td>\n",
       "      <td>0.39000</td>\n",
       "      <td>10.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>3.20000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>11.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>1</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>0.99239</td>\n",
       "      <td>3.38000</td>\n",
       "      <td>0.59000</td>\n",
       "      <td>10.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>1</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.98984</td>\n",
       "      <td>3.01000</td>\n",
       "      <td>0.35000</td>\n",
       "      <td>12.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5316</th>\n",
       "      <td>1</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>0.99910</td>\n",
       "      <td>3.17000</td>\n",
       "      <td>0.58000</td>\n",
       "      <td>8.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>1</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.99500</td>\n",
       "      <td>3.36000</td>\n",
       "      <td>0.48000</td>\n",
       "      <td>9.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5329</th>\n",
       "      <td>0</td>\n",
       "      <td>7.150006</td>\n",
       "      <td>0.465566</td>\n",
       "      <td>0.358006</td>\n",
       "      <td>4.847456</td>\n",
       "      <td>0.194392</td>\n",
       "      <td>48.662868</td>\n",
       "      <td>163.655312</td>\n",
       "      <td>0.99365</td>\n",
       "      <td>3.72359</td>\n",
       "      <td>0.80892</td>\n",
       "      <td>12.78763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1066 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \\\n",
       "0        1       6.900000          0.290000     0.320000        5.800000   \n",
       "3        1       6.700000          0.220000     0.330000        1.200000   \n",
       "7        0       8.200000          1.000000     0.090000        2.300000   \n",
       "10       1       6.300000          0.360000     0.300000        4.800000   \n",
       "20       1       6.900000          0.190000     0.490000        6.600000   \n",
       "...    ...            ...               ...          ...             ...   \n",
       "5302     1       5.800000          0.300000     0.120000        1.600000   \n",
       "5315     1       8.900000          0.270000     0.280000        0.800000   \n",
       "5316     1       6.600000          0.350000     0.290000       14.400000   \n",
       "5328     1       6.900000          0.190000     0.350000        5.000000   \n",
       "5329     0       7.150006          0.465566     0.358006        4.847456   \n",
       "\n",
       "      chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density       ph  \\\n",
       "0      0.040000            16.000000            112.000000  0.99300  3.04000   \n",
       "3      0.036000            36.000000             86.000000  0.99058  3.10000   \n",
       "7      0.065000             7.000000             37.000000  0.99685  3.32000   \n",
       "10     0.049000            14.000000             85.000000  0.99320  3.28000   \n",
       "20     0.036000            49.000000            172.000000  0.99320  3.20000   \n",
       "...         ...                  ...                   ...      ...      ...   \n",
       "5302   0.036000            57.000000            163.000000  0.99239  3.38000   \n",
       "5315   0.024000            29.000000            128.000000  0.98984  3.01000   \n",
       "5316   0.044000            54.000000            177.000000  0.99910  3.17000   \n",
       "5328   0.067000            32.000000            150.000000  0.99500  3.36000   \n",
       "5329   0.194392            48.662868            163.655312  0.99365  3.72359   \n",
       "\n",
       "      sulphates   alcohol  \n",
       "0       0.58000  11.20000  \n",
       "3       0.76000  11.40000  \n",
       "7       0.55000   9.00000  \n",
       "10      0.39000  10.60000  \n",
       "20      0.27000  11.50000  \n",
       "...         ...       ...  \n",
       "5302    0.59000  10.50000  \n",
       "5315    0.35000  12.40000  \n",
       "5316    0.58000   8.90000  \n",
       "5328    0.48000   9.80000  \n",
       "5329    0.80892  12.78763  \n",
       "\n",
       "[1066 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d6b24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "8\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in y_rfc_pred:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67c6199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}, '4': {'precision': 0.375, 'recall': 0.07142857142857142, 'f1-score': 0.12, 'support': 42}, '5': {'precision': 0.6324786324786325, 'recall': 0.6032608695652174, 'f1-score': 0.6175243393602226, 'support': 368}, '6': {'precision': 0.551948051948052, 'recall': 0.7456140350877193, 'f1-score': 0.6343283582089553, 'support': 456}, '7': {'precision': 0.5681818181818182, 'recall': 0.3067484662576687, 'f1-score': 0.39840637450199207, 'support': 163}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 32}, '9': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'accuracy': 0.5769230769230769, 'macro avg': {'precision': 0.44680121465835754, 'recall': 0.24672170604845384, 'f1-score': 0.25289415315302427, 'support': 1066}, 'weighted avg': {'precision': 0.557039479178316, 'recall': 0.5769230769230769, 'f1-score': 0.5501716015681709, 'support': 1066}}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)\n",
    "# metrics = classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df2e3fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 0.721659066438534\n",
      "SVR RMSE: 0.8114404713393576\n",
      "Gradient Boosting Regressor RMSE: 0.6949564642541116\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test are your feature and target variables\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train.values.ravel())\n",
    "y_pred_linear = linear_reg.predict(X_test)\n",
    "rmse_linear = np.sqrt(mean_squared_error(y_test, y_pred_linear))\n",
    "print(\"Linear Regression RMSE:\", rmse_linear)\n",
    "\n",
    "# Support Vector Regression (SVR)\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train.values.ravel())\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "rmse_svr = np.sqrt(mean_squared_error(y_test, y_pred_svr))\n",
    "print(\"SVR RMSE:\", rmse_svr)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train.values.ravel())\n",
    "y_pred_gbr = gbr.predict(X_test)\n",
    "rmse_gbr = np.sqrt(mean_squared_error(y_test, y_pred_gbr))\n",
    "print(\"Gradient Boosting Regressor RMSE:\", rmse_gbr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7826f8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading model files (0 dirs, 0 files):  17%|▋   | 1/6 [00:00<00:02,  2.09it/s]\n",
      "Uploading: 0.000%|                        | 0/11752481 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 8.922%|█▏            | 1048576/11752481 elapsed<00:02 remaining<00:26\u001b[A\n",
      "Uploading: 26.767%|███▍         | 3145728/11752481 elapsed<00:03 remaining<00:07\u001b[A\n",
      "Uploading: 26.767%|███▍         | 3145728/11752481 elapsed<00:03 remaining<00:07\u001b[A\n",
      "Uploading: 35.689%|████▋        | 4194304/11752481 elapsed<00:05 remaining<00:09\u001b[A\n",
      "Uploading: 53.533%|██████▉      | 6291456/11752481 elapsed<00:06 remaining<00:04\u001b[A\n",
      "Uploading: 62.455%|████████     | 7340032/11752481 elapsed<00:15 remaining<00:12\u001b[A\n",
      "Uploading: 71.377%|█████████▎   | 8388608/11752481 elapsed<00:16 remaining<00:07\u001b[A\n",
      "Uploading: 80.300%|██████████▍  | 9437184/11752481 elapsed<00:16 remaining<00:03\u001b[A\n",
      "Uploading: 91.078%|██████████▉ | 10703905/11752481 elapsed<00:18 remaining<00:01\u001b[A\n",
      "Uploading: 100.000%|███████████| 11752481/11752481 elapsed<00:20 remaining<00:00\u001b[A\n",
      "Uploading input_example and model_schema:  33%|█  | 2/6 [00:21<00:49, 12.42s/it]\n",
      "Uploading: 0.000%|                            | 0/1066 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 100.000%|███████████████████| 1066/1066 elapsed<00:01 remaining<00:00\u001b[A\n",
      "Model export complete: 100%|██████████████████████| 6/6 [00:28<00:00,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/210070/models/wine_model/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'wine_model', version: 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will now upload our model to the Hopsworks Model Registry. First get an object for the model registry.\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# The contents of the 'wine_model' directory will be saved to the model registry. Create the dir, first.\n",
    "model_dir=\"wine_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save our rf_model(random forest) to 'model_dir', whose contents will be uploaded to the model registry\n",
    "joblib.dump(rf_model, model_dir + \"/wine_model.pkl\")   \n",
    "\n",
    "# Specify the schema of the model's input/output using the features (X_train) and labels (y_train)\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema, output_schema)\n",
    "\n",
    "# Create an entry in the model registry that includes the model's name, desc, metrics\n",
    "wine_model = mr.python.create_model(\n",
    "    name=\"wine_model\", \n",
    "    metrics={\"rmse\" : rmse},\n",
    "    model_schema=model_schema,\n",
    "    description=\"Wine Quality Predictor\"\n",
    ")\n",
    "\n",
    "# Upload the model to the model registry, including all files in 'model_dir'\n",
    "wine_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dae836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
